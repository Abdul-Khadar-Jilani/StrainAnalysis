<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Blink & Distance — MediaPipe (WASM)</title>
  <style>
    :root { --bg:#0b1020; --fg:#e9edf1; --muted:#9fb0c3; --accent:#7bdcff; }
    html,body{height:100%}
    body{margin:0; font:14px/1.45 system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji"; background:var(--bg); color:var(--fg);}
    header{display:flex; gap:12px; align-items:center; padding:12px 16px; border-bottom:1px solid #1a2138; position:sticky; top:0; background:linear-gradient(180deg, rgba(11,16,32,.98), rgba(11,16,32,.9)); backdrop-filter: blur(8px); z-index:10}
    header h1{font-size:16px; font-weight:700; margin:0}
    header .pill{font-size:12px; color:#07131b; background:var(--accent); border-radius:999px; padding:2px 8px; font-weight:700}
    main{display:grid; grid-template-columns: 1.2fr .8fr; gap:16px; padding:16px; max-width:1100px; margin:0 auto}
    section.card{background:#0e1430; border:1px solid #1a2138; border-radius:16px; overflow:hidden; box-shadow:0 10px 30px rgba(0,0,0,.25)}
    .card h2{margin:0; padding:10px 12px; font-size:13px; color:var(--muted); border-bottom:1px solid #1a2138}
    .video-wrap{position:relative;}
    video, canvas{display:block; width:100%; height:auto;}
    canvas{position:absolute; inset:0; pointer-events:none}
    .controls{display:flex; flex-wrap:wrap; gap:8px; padding:12px}
    .controls > *{background:#0b122b; border:1px solid #1a2138; color:var(--fg); border-radius:10px; padding:8px 10px}
    .controls input[type="number"]{width:90px}
    .controls button{cursor:pointer; font-weight:700}
    .metrics{display:grid; grid-template-columns:repeat(2,1fr); gap:8px; padding:12px}
    .metric{border:1px solid #1a2138; background:#0b122b; border-radius:12px; padding:12px}
    .metric h3{margin:0 0 4px 0; font-size:12px; color:var(--muted)}
    .metric .val{font-size:22px; font-weight:800}
    .good{color:#7bffb8}
    .warn{color:#ffd27b}
    .bad{color:#ff7b9e}
    .footer{padding:10px 12px; font-size:12px; color:var(--muted)}
    .toast{position:fixed; right:16px; bottom:16px; background:#0b122b; border:1px solid #1a2138; color:var(--fg); padding:10px 12px; border-radius:12px; box-shadow:0 10px 30px rgba(0,0,0,.35); display:none}
    .toast.show{display:block}
    .row{display:flex; align-items:center; gap:8px}
    .hint{font-size:12px; color:var(--muted)}
    a{color:var(--accent)}
  </style>
</head>
<body>
  <header>
    <h1>Blink & Distance (on-device, WebAssembly)</h1>
    <span class="pill">MediaPipe Tasks</span>
  </header>

  <main>
    <section class="card">
      <h2>Camera</h2>
      <div class="video-wrap">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="overlay"></canvas>
      </div>
      <div class="controls">
        <button id="btnStart">Start camera</button>
        <button id="btnStop" disabled>Stop</button>
        <label class="row">Known distance (cm): <input id="knownDist" type="number" min="10" max="200" value="50"></label>
        <button id="btnCalib" title="Look straight, good lighting">Calibrate</button>
        <span class="hint">Tip: sit ~50–60 cm away, click Calibrate.</span>
      </div>
      <div class="footer">
        Processing is fully on-device; video never leaves your browser.
      </div>
    </section>

    <section class="card">
      <h2>Metrics</h2>
      <div class="metrics">
        <div class="metric"><h3>EAR (avg)</h3><div id="mEAR" class="val">–</div></div>
        <div class="metric"><h3>Distance</h3><div id="mDist" class="val">–</div></div>
        <div class="metric"><h3>Blinks (last min)</h3><div id="mBPM" class="val">0</div></div>
        <div class="metric"><h3>Lifetime blinks</h3><div id="mBLife" class="val">0</div></div>
      </div>
      <div class="footer hint">
        Blink = EAR &lt; threshold for ~80 ms. Distance uses iris scale after a one‑click calibration.
      </div>
    </section>
  </main>

  <div id="toast" class="toast"></div>

  <script type="module">
    import vision from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";
    const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;

    // --- DOM
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const mEAR = document.getElementById('mEAR');
    const mDist = document.getElementById('mDist');
    const mBPM = document.getElementById('mBPM');
    const mBLife = document.getElementById('mBLife');
    const toast = document.getElementById('toast');
    const btnStart = document.getElementById('btnStart');
    const btnStop = document.getElementById('btnStop');
    const btnCalib = document.getElementById('btnCalib');
    const knownDist = document.getElementById('knownDist');

    // --- State
    let landmarker; let running = false; let lastTs = -1;
    let blinkCounter = 0, lifetimeBlinks = 0;  // per-minute & lifetime
    const blinkTimes = []; // timestamps (ms) of blink events
    let earBelowSince = null; // ms timestamp once EAR < threshold
    const BLINK_EAR_THR = 0.21;          // tune if needed
    const BLINK_MIN_MS = 80;             // how long EAR must stay below
    const BLINK_COOLDOWN_MS = 150;       // prevent double count
    let lastBlinkAt = 0;

    // Distance calibration:  K = knownDistanceCm * irisPx
    let K = null; // if null, we show only EAR/blinks until user calibrates
    let lastBadDistStart = null; // for 60s posture warning

    // Eye + Iris indices (MediaPipe FaceMesh canonical)
    // See: LearnOpenCV & Mediapipe docs; EAR points: 6 per eye (P1..P6)
    const R = [33, 160, 158, 133, 153, 144];
    const L = [362, 385, 387, 263, 373, 380];
    const RIGHT_IRIS = [469, 470, 471, 472];
    const LEFT_IRIS  = [474, 475, 476, 477];

    function dist(a,b)
        { 
            const dx=a.x-b.x, dy=a.y-b.y; 
            return Math.hypot(dx,dy); 
        }
    function ear(landmarks, idxs){
      const [p1,p2,p3,p4,p5,p6] = idxs.map(i=>landmarks[i]);
      const v1 = dist(p2,p6); // (p2, p6)
      const v2 = dist(p3,p5); // (p3, p5)
      const h  = dist(p1,p4); // (p1, p4)
      const e  = (v1+v2)/(2*h);
      return e;
    }
    function irisWidthPx(landmarks){
      // choose larger width across both eyes (in pixels of the input image space)
      const eyes = [RIGHT_IRIS, LEFT_IRIS];
      let maxW = null;
      for(const arr of eyes){
        const pts = arr.map(i=>landmarks[i]);
        // bounding box width in normalized coords, scale by video width
        const xs = pts.map(p=>p.x), ys = pts.map(p=>p.y);
        const w = (Math.max(...xs)-Math.min(...xs)) * video.videoWidth;
        const h = (Math.max(...ys)-Math.min(...ys)) * video.videoHeight;
        const d = Math.max(w,h);
        if(!maxW || d>maxW) maxW = d;
      }
      return maxW; // pixels
    }
    function showToast(msg){
      toast.textContent = msg; toast.classList.add('show');
      clearTimeout(showToast._t);
      showToast._t = setTimeout(()=>toast.classList.remove('show'), 3000);
    }

    async function initModel(){
      const resolver = await FilesetResolver.forVisionTasks(
        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm'
      );
      landmarker = await FaceLandmarker.createFromOptions(resolver,{
        baseOptions:{
          modelAssetPath:'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
          delegate:'GPU'
        },
        runningMode:'VIDEO',
        numFaces:1,
        outputFaceBlendshapes:false
      });
    }

    async function startCamera(){
      await initModel();
      const stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:'user', width:{ideal:640}, height:{ideal:480}}, audio:false});
      video.srcObject = stream;
      await video.play();
      overlay.width = video.videoWidth; overlay.height = video.videoHeight;
      running = true; btnStart.disabled = true; btnStop.disabled = false;
      requestAnimationFrame(loop);
      showToast('Camera started');
    }
    function stopCamera(){
      running = false; btnStart.disabled = false; btnStop.disabled = true;
      const s = video.srcObject; if(s){ s.getTracks().forEach(t=>t.stop()); }
      video.srcObject = null; ctx.clearRect(0,0,overlay.width, overlay.height);
    }

    function loop(ts){
      if(!running) return;
      if(lastTs === ts){ return requestAnimationFrame(loop); }
      lastTs = ts;
      const res = landmarker.detectForVideo(video, ts);
      ctx.clearRect(0,0,overlay.width, overlay.height);
      if(res.faceLandmarks && res.faceLandmarks.length){
        const lm = res.faceLandmarks[0];
        // Draw eyes for visual sanity
        const draw = new DrawingUtils(ctx);
        draw.drawConnectors(lm, R.map((v,i)=>[R[i], R[(i+1)%R.length]]).flat(), {color:'#7bdcff'});
        draw.drawConnectors(lm, L.map((v,i)=>[L[i], L[(i+1)%L.length]]).flat(), {color:'#7bdcff'});

        const earR = ear(lm, R);
        const earL = ear(lm, L);
        const earAvg = (earR+earL)/2;
        mEAR.textContent = earAvg.toFixed(2);

        // Blink logic
        const now = performance.now();
        if(earAvg < BLINK_EAR_THR){
          if(earBelowSince === null) earBelowSince = now;
        } else {
          if(earBelowSince !== null){
            const dur = now - earBelowSince;
            if(dur >= BLINK_MIN_MS && (now - lastBlinkAt) > BLINK_COOLDOWN_MS){
              lifetimeBlinks += 1; mBLife.textContent = String(lifetimeBlinks);
              blinkTimes.push(now); lastBlinkAt = now;
            }
          }
          earBelowSince = null;
        }
        // blinks/min over sliding 60s
        const cutoff = now - 60_000;
        while(blinkTimes.length && blinkTimes[0] < cutoff) blinkTimes.shift();
        mBPM.textContent = String(blinkTimes.length);

        // Distance
        const irisPx = irisWidthPx(lm); // in px
        if(K){
          const distCm = K / irisPx; // since K = knownCm * irisPx_at_known
          mDist.textContent = `${distCm.toFixed(1)} cm`;
          // posture warning if <30 cm for > 60s
          if(distCm < 30){
            if(!lastBadDistStart) lastBadDistStart = now;
            else if(now - lastBadDistStart > 60_000){
              showToast(`⚠️ Too close for a minute (${distCm.toFixed(0)} cm)`);
              lastBadDistStart = now + 5_000; // avoid spamming; next warn in ~5s+60s condition
            }
          } else {
            lastBadDistStart = null;
          }
        } else {
          mDist.textContent = 'Calibrate';
        }
      }
      requestAnimationFrame(loop);
    }

    btnStart.onclick = startCamera;
    btnStop.onclick = stopCamera;
    btnCalib.onclick = ()=>{
      if(!landmarker || !video.videoWidth){ return showToast('Start camera first'); }
      const res = landmarker.detectForVideo(video, performance.now());
      if(!res.faceLandmarks?.length){ return showToast('No face detected'); }
      const lm = res.faceLandmarks[0];
      const irisPx = irisWidthPx(lm);
      const cm = parseFloat(knownDist.value || '50');
      if(irisPx && cm>0){
        K = cm * irisPx; // simple proportional calibration
        showToast(`Calibrated at ${cm} cm`);
      } else {
        showToast('Calibration failed, try again');
      }
    };
  </script>

  <!--
    Notes:
    • Uses @mediapipe/tasks-vision (WASM) with GPU delegate to run fully on-device.
    • Model path and WASM loader are pulled from Google’s official CDN.
    • Blink detection via EAR with MediaPipe FaceMesh indices.
    • Distance uses a single-point proportional calibration based on iris width in pixels.
  -->
</body>
</html>
